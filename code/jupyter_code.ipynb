{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tfv1\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = tf.constant(2)\n",
    "m = tf.constant([[1,2],[3,4]])\n",
    "m = tf.constant([1,2,3,4],shape=[2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    s = tf.constant(2)\n",
    "    m = tf.constant([[1,2],[3,4]])\n",
    "    mmul = s*m\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tfv1.Session(graph=g) as sess:\n",
    "    print(sess.run(mmul))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    w = tf.Variable(tf.ones((2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tfv1.Session(graph=g) as sess:\n",
    "    print(sess.run(w))\n",
    "    # It will give u an error because you haven't initialize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tfv1.Session(graph=g) as sess:\n",
    "    sess.run(tfv1.global_variables_initializer())\n",
    "    print(sess.run(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tfv1.Session(graph=g) as sess:\n",
    "    sess.run(tfv1.global_variables_initializer())\n",
    "    print(sess.run(w))\n",
    "    sess.run(w.assign(tf.zeros((2,2))))\n",
    "    print(sess.run(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\left( {\\begin{array}{*{20}{c}}\n",
    "{\\rm{4}}&{\\rm{5}}\n",
    "\\end{array}} \\right){\\rm{ = }}\\left( {\\begin{array}{*{20}{c}}\n",
    "{\\rm{1}}&{\\rm{2}}\n",
    "\\end{array}} \\right)\\left( {\\begin{array}{*{20}{c}}\n",
    "{\\rm{1}}&{\\rm{1}}\\\\\n",
    "{\\rm{1}}&{\\rm{1}}\n",
    "\\end{array}} \\right){\\rm{ + }}\\left( {\\begin{array}{*{20}{c}}\n",
    "{\\rm{1}}&{\\rm{2}}\n",
    "\\end{array}} \\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "tfv1.disable_eager_execution()\n",
    "with g.as_default():\n",
    "    node1 = tfv1.placeholder(tf.float32,shape = [1,2])\n",
    "    node2 = tfv1.placeholder(tf.float32,shape = [1,2])\n",
    "    w_linear = tf.matmul(node1,w) + node2\n",
    "with tfv1.Session(graph=g) as sess:\n",
    "    sess.run(tfv1.global_variables_initializer())\n",
    "    print(sess.run(w))\n",
    "    print(sess.run(w_linear,feed_dict={node1:np.matrix([1.0,2.0]),node2:np.matrix([1.0,2.0])}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(3.0)\n",
    "with tf.GradientTape() as tape:\n",
    "  y = x**2\n",
    "dy_dx = tape.gradient(y, x)\n",
    "# dy = 2x * dx\n",
    "with tfv1.Session() as sess:\n",
    "    sess.run(tfv1.global_variables_initializer())\n",
    "    print(sess.run(dy_dx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = tf.Variable(3.0, name='x0')\n",
    "x1 = tf.Variable(3.0, name='x1', trainable=False)\n",
    "x2 = tf.Variable(2.0, name='x2') + 1.0\n",
    "x3 = tf.constant(3.0, name='x3')\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "  y = (x0**2) + (x1**2) + (x2**2) \n",
    "\n",
    "# change x0 to more ?\n",
    "grad = tape.gradient(y, [x0])\n",
    "\n",
    "with tfv1.Session() as sess:\n",
    "    sess.run(tfv1.global_variables_initializer())\n",
    "    print(sess.run(grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = tf.constant(1)\n",
    "t2 = tf.constant(2)\n",
    "def f1(): return t1+t2\n",
    "def f2(): return t1-t2\n",
    "res = tf.cond(t1<t2,f1,f2)\n",
    "with tfv1.Session() as sess:\n",
    "    print(sess.run(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = tf.constant(1)\n",
    "t2 = tf.constant(5)\n",
    "body = (tf.add(t1,1),t2)\n",
    "def cond(t1,t2): return t1<t2\n",
    "def body(t1,t2): \n",
    "    t1 = tf.add(t1,1)\n",
    "    return [t1,t2]\n",
    "res = tf.while_loop(cond,body,[t1,t2])\n",
    "with tfv1.Session() as sess:\n",
    "    print(sess.run(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## notice the difference between [t1,t2] and (t1,t2)\n",
    "t1 = tf.constant(1)\n",
    "t2 = tf.constant(5)\n",
    "body = (tf.add(t1,1),t2)\n",
    "def cond(t1,t2): return t1<t2\n",
    "def body(t1,t2): \n",
    "    t1 = tf.add(t1,1)\n",
    "    return (t1,t2)\n",
    "res = tf.while_loop(cond,body,(t1,t2))\n",
    "with tfv1.Session() as sess:\n",
    "    print(sess.run(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  # Example of Linear Rregression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct one iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### True model $Y = X\\left( {\\begin{array}{*{20}{c}}\n",
    "1\\\\\n",
    "5\n",
    "\\end{array}} \\right) + \\varepsilon ,\\varepsilon  \\sim N\\left( {0,1} \\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tfv1\n",
    "tfv1.disable_eager_execution()\n",
    "n_size = 5000\n",
    "X = np.random.normal(0.0,1.0,size=(n_size ,2))\n",
    "## beta real = (1.0,5.0)\n",
    "Y = np.dot(X,np.matrix([[1.0],[5.0]])) + np.random.normal(0.0,1.0,size=(n_size ,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = tf.Variable(np.array([[0.0],[0.0]]))\n",
    "with tf.GradientTape() as tape:\n",
    "    error = tf.subtract(Y,tf.matmul(X,beta))\n",
    "    loss = tf.reduce_mean(tf.multiply(error,error))\n",
    "grad = beta - 0.5*tape.gradient(loss,beta)\n",
    "with tfv1.Session() as sess:\n",
    "    sess.run(tfv1.global_variables_initializer())\n",
    "    print(sess.run(grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear_Regression():\n",
    "    tfv1.reset_default_graph()\n",
    "    def __init__(self):\n",
    "        self.beta = tf.Variable(np.array([[0.0],[0.0]]),dtype='float64',name='beta')\n",
    "        \n",
    "    def loss(self,x,y):\n",
    "        error = tf.subtract(y,tf.matmul(x,self.beta))\n",
    "        loss = tf.reduce_mean(tf.multiply(error,error))\n",
    "        return loss\n",
    "    \n",
    "    def coefficient(self):\n",
    "        with tfv1.Session() as sess:\n",
    "            new_saver = tfv1.train.import_meta_graph('my-model.meta')\n",
    "            new_saver.restore(sess,'my-model')\n",
    "            return (sess.run(self.beta))\n",
    "    \n",
    "    def fit(self,x,y,gamma=0.5):\n",
    "        maxit = 100\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(self.beta)\n",
    "            curent_loss = self.loss(x=X,y=Y)\n",
    "        dw = tape.gradient(curent_loss,self.beta)\n",
    "        self.beta = self.beta.assign_sub(gamma * dw)\n",
    "        with tfv1.Session() as sess:\n",
    "            sess.run(tfv1.global_variables_initializer())\n",
    "            for it in range(maxit):\n",
    "                print(sess.run(self.beta))\n",
    "            print(sess.run(self.beta))\n",
    "            saver = tfv1.train.Saver()\n",
    "            saver.save(sess, 'my-model')\n",
    "    \n",
    "    def predict(self,x):\n",
    "        y_predict = tf.matmul(x,self.beta)\n",
    "        with tfv1.Session() as sess:\n",
    "            new_saver = tfv1.train.import_meta_graph('my-model.meta')\n",
    "            new_saver.restore(sess,'my-model')\n",
    "            return sess.run(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Linear_Regression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimation ${{\\hat \\beta }^{\\left( {100} \\right)}} = ?$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(x=np.ones((1,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coefficient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of sport data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data description: 200 games from the English Premier League, we take the sentiment score from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_english = pd.read_csv('extract-betsentiment-com.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_english_prepare = data_english[['sentiment_score_st_a','sentiment_score_st_b','sentiment_score_lt_a','sentiment_score_lt_b','wgted_players_sentiment_a','wgted_players_sentiment_b','wgted_players_sentiment_st_a','wgted_players_sentiment_st_b','final_result']]\n",
    "data_english_prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_english_prepare.iloc[:,0:-1],data_english_prepare.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_dm = pd.get_dummies(y_train)\n",
    "y_test_dm = pd.get_dummies(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[<img src=\"https://www.tensorflow.org/images/custom_estimators/full_network.png\">](https://www.tensorflow.org/tutorials/customization/custom_training_walkthrough)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_model(hidden_nodes, num_iters):\n",
    "    \n",
    "    # Reset the graph\n",
    "    tfv1.reset_default_graph()\n",
    "\n",
    "    # Placeholders for input and output data\n",
    "    X = tfv1.placeholder(shape=(150, 8), dtype=tf.float64, name='X')\n",
    "    y = tfv1.placeholder(shape=(150, 3), dtype=tf.float64, name='y')\n",
    "\n",
    "    # Variables for two group of weights between the three layers of the network\n",
    "    W1 = tf.Variable(np.random.rand(8, hidden_nodes), dtype=tf.float64)\n",
    "    W2 = tf.Variable(np.random.rand(hidden_nodes, 3), dtype=tf.float64)\n",
    "\n",
    "    # Create the neural net graph\n",
    "    A1 = tf.sigmoid(tf.matmul(X, W1))\n",
    "    y_est = tf.sigmoid(tf.matmul(A1, W2))\n",
    "\n",
    "    # Define a loss function\n",
    "    deltas = tf.square(y_est - y)\n",
    "    loss = tf.reduce_sum(deltas)\n",
    "\n",
    "    # Define a train operation to minimize the loss\n",
    "    optimizer = tfv1.train.GradientDescentOptimizer(0.005)\n",
    "    train = optimizer.minimize(loss)\n",
    "\n",
    "    # Initialize variables and run session\n",
    "    init = tfv1.global_variables_initializer()\n",
    "    sess = tfv1.Session()\n",
    "    sess.run(init)\n",
    "\n",
    "    # Go through num_iters iterations\n",
    "    for i in range(num_iters):\n",
    "        sess.run(train, feed_dict={X: X_train.values, y: y_train_dm.values})\n",
    "        loss_plot[hidden_nodes].append(sess.run(loss, feed_dict={X: X_train.values, y: y_train_dm.values}))\n",
    "        weights1 = sess.run(W1)\n",
    "        weights2 = sess.run(W2)\n",
    "        \n",
    "    print(\"loss (hidden nodes: %d, iterations: %d): %.2f\" % (hidden_nodes, num_iters, loss_plot[hidden_nodes][-1]))\n",
    "    sess.close()\n",
    "    return weights1, weights2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "tfv1.disable_eager_execution()\n",
    "num_hidden_nodes = [5, 10, 20]\n",
    "loss_plot = {5: [], 10: [], 20: []}\n",
    "weights1 = {5: None, 10: None, 20: None}\n",
    "weights2 = {5: None, 10: None, 20: None}\n",
    "num_iters = 2000\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "for hidden_nodes in num_hidden_nodes:\n",
    "    weights1[hidden_nodes], weights2[hidden_nodes] = create_train_model(hidden_nodes, num_iters)\n",
    "    plt.plot(range(num_iters), loss_plot[hidden_nodes], label=\"nn: 8-%d-3\" % hidden_nodes)\n",
    "    \n",
    "plt.xlabel('Iteration', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.legend(fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN():\n",
    "    tfv1.reset_default_graph()\n",
    "    \n",
    "    def __init__(self,hidden_nodes):\n",
    "        self.W1 = tf.Variable(np.random.rand(8, hidden_nodes), dtype=tf.float64, name = 'W1')\n",
    "        self.W2 = tf.Variable(np.random.rand(hidden_nodes, 3), dtype=tf.float64, name = 'W2')\n",
    "        \n",
    "    def loss(self,y1,y2):\n",
    "        error = tf.subtract(y1,y2)\n",
    "        loss = tf.reduce_mean(tf.multiply(error,error))\n",
    "        return loss\n",
    "    \n",
    "    def coefficient(self):\n",
    "        with tfv1.Session() as sess:\n",
    "            new_saver = tfv1.train.import_meta_graph('my-model.meta')\n",
    "            new_saver.restore(sess,'my-model')\n",
    "            return (sess.run(self.W1),sess.run(self.W2))\n",
    "    \n",
    "    def fit(self,x_in,y_in,gamma=0.5):\n",
    "        maxit = 2000\n",
    "        X = tfv1.placeholder(shape=(150, 8), dtype=tf.float64, name='X')\n",
    "        y = tfv1.placeholder(shape=(150, 3), dtype=tf.float64, name='y')\n",
    "        A1 = tf.sigmoid(tf.matmul(X, self.W1))\n",
    "        y_est = tf.sigmoid(tf.matmul(A1, self.W2))\n",
    "        curent_loss = self.loss(y1=y_est,y2=y)\n",
    "        optimizer = tfv1.train.GradientDescentOptimizer(0.005)\n",
    "        train = optimizer.minimize(curent_loss)\n",
    "        with tfv1.Session() as sess:\n",
    "            sess.run(tfv1.global_variables_initializer())\n",
    "            for it in range(maxit):\n",
    "                sess.run(train, feed_dict={X: x_in, y: y_in})\n",
    "                print(sess.run(curent_loss, feed_dict={X: x_in, y: y_in}))\n",
    "                print(sess.run(self.W1))\n",
    "            saver = tfv1.train.Saver()\n",
    "            saver.save(sess, 'my-model')\n",
    "    \n",
    "    def predict(self,x):\n",
    "        y_predict = tf.sigmoid(tf.matmul(tf.matmul(x,self.W1),self.W2))\n",
    "        with tfv1.Session() as sess:\n",
    "            new_saver = tfv1.train.import_meta_graph('my-model.meta')\n",
    "            new_saver.restore(sess,'my-model')\n",
    "            return sess.run(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train.values,y_train_dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coefficient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X_test.iloc[0,:].values.astype('float64').reshape(1,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
